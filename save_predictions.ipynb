{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "save_predictions.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GEyW8nj9a_A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8af44b95-66c9-4f70-db54-13a72cf8f2cc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wb1Qr2vfEdbJ"
      },
      "source": [
        "#Importing required libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6kw6NaV6j8G"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import math\n",
        "from PIL import Image\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow import keras\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAJWCUfWGecg"
      },
      "source": [
        "#Defining paths for inputting data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltTEdWpL6mwP"
      },
      "source": [
        "# Path to root folder\n",
        "root_dir = '/content/drive/MyDrive/slices/'\n",
        "\n",
        "# Path for training data\n",
        "train_dir = os.path.join(root_dir, 'train')\n",
        "train_image_dir = os.path.join(train_dir, 'Images')\n",
        "train_label_dir = os.path.join(train_dir, 'Labels')\n",
        "train_predict_dir = os.path.join(train_dir, 'Predictions/')\n",
        "\n",
        "# Path for validation data\n",
        "validate_dir = os.path.join(root_dir, 'validate/')\n",
        "validate_image_dir = os.path.join(validate_dir, 'Images')\n",
        "validate_label_dir = os.path.join(validate_dir, 'Labels')\n",
        "validate_predict_dir = os.path.join(validate_dir, 'Predictions/')\n",
        "\n",
        "# Path for testing data\n",
        "test_dir = os.path.join(root_dir, 'test')\n",
        "test_image_dir = os.path.join(test_dir, 'Images')\n",
        "test_predict_dir = os.path.join(test_dir, 'Predictions/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-NWhI35Gkza"
      },
      "source": [
        "#Defining some constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nm1ls7i7Zxr"
      },
      "source": [
        "SEED = 909\n",
        "TRAIN_BATCH_SIZE = 64\n",
        "VALIDATION_BATCH_SIZE = 64\n",
        "TEST_BATCH_SIZE = 64\n",
        "\n",
        "TRAIN_SIZE = 21894\n",
        "VALIDATE_SIZE = 6551\n",
        "TEST_SIZE = 6531\n",
        "\n",
        "HEIGHT = 128\n",
        "WIDTH = 128\n",
        "IMAGE_SIZE = (HEIGHT,WIDTH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMKRq32hGn2G"
      },
      "source": [
        "#Creating DataGenerators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_3PTswk6uP-"
      },
      "source": [
        "# Training generator\n",
        "def training_generator(imgPath):\n",
        "    data_gen_args = dict(rescale=1./255\n",
        "#                      featurewise_center=True,\n",
        "#                      featurewise_std_normalization=True,\n",
        "#                      rotation_range=90\n",
        "#                      width_shift_range=0.2,\n",
        "#                      height_shift_range=0.2,\n",
        "#                      zoom_range=0.3\n",
        "                        )\n",
        "    datagen = ImageDataGenerator(**data_gen_args)\n",
        "    \n",
        "    image_generator = datagen.flow_from_directory(imgPath, target_size=IMAGE_SIZE, class_mode=None, color_mode='grayscale', batch_size=1, seed=SEED, shuffle=False)\n",
        "    return image_generator\n",
        "\n",
        "# Validation generator\n",
        "def validation_generator(imgPath):\n",
        "    data_gen_args = dict(rescale=1./255)\n",
        "    datagen = ImageDataGenerator(**data_gen_args)\n",
        "    \n",
        "    image_generator = datagen.flow_from_directory(imgPath, target_size=IMAGE_SIZE, class_mode=None, color_mode='grayscale', batch_size=1, seed=SEED, shuffle=False)\n",
        "    return image_generator\n",
        "\n",
        "# Testing generator\n",
        "def testing_generator(imgPath):\n",
        "    data_gen_args = dict(rescale=1./255)\n",
        "    datagen = ImageDataGenerator(**data_gen_args)\n",
        "    \n",
        "    image_generator = datagen.flow_from_directory(imgPath, target_size=IMAGE_SIZE, class_mode=None, color_mode='grayscale', batch_size=1, seed=SEED, shuffle = False)\n",
        "    return image_generator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kT6eJvAi7GaB",
        "outputId": "05c605c1-0f3b-4876-ee90-0c36f93888df"
      },
      "source": [
        "train_generator=training_generator(train_image_dir)\n",
        "validate_generator=validation_generator(validate_image_dir)\n",
        "test_generator=testing_generator(test_image_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 21894 images belonging to 1 classes.\n",
            "Found 6551 images belonging to 1 classes.\n",
            "Found 6531 images belonging to 1 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZC_2lQ1Gsvj"
      },
      "source": [
        "#Loading saved model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcr2bjsQ-N4a"
      },
      "source": [
        "model = load_model(\"/content/drive/MyDrive/slices/results/model.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TmnpdTUGyHF"
      },
      "source": [
        "#Saving predictions for training, validation and testing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dMx_8Zc9xY4"
      },
      "source": [
        "def save_predictions(datagen, samples, imagePath, predictPath):\n",
        "  path = os.path.join(imagePath, 'Images/')\n",
        "  files = os.listdir(path)\n",
        "  files.sort(reverse=False)\n",
        "  for i, file in zip(range(0,samples), files):\n",
        "    img = cv2.imread(os.path.join(path,file))\n",
        "    a, b = os.path.split(path+file)\n",
        "    x, y = os.path.splitext(b)\n",
        "    image = next(datagen)\n",
        "    pred = model.predict(image)[0] > 0.5\n",
        "    pred = np.squeeze(pred, axis=None)\n",
        "    print(\"Saving \" + str(b) + \" file\")\n",
        "    plt.imsave(os.path.join(predictPath, str(x) + \".png\"), pred, cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3t1ySduj-wld"
      },
      "source": [
        "save_predictions(train_generator, TRAIN_SIZE, train_image_dir, train_predict_dir) # Passing training data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omB1NdOHmnf0"
      },
      "source": [
        "save_predictions(validate_generator, VALIDATE_SIZE, validate_image_dir, validate_predict_dir) # Passing valiation data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ao3o5QzIHdTa"
      },
      "source": [
        "save_predictions(test_generator, TEST_SIZE, test_image_dir, test_predict_dir) # Passing test data"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}